[base]
split_size = 0.1
log_dir = log/
log_level = 10
num_labels = 10

[TextCNN]
loss_type = ce_loss
dropout = 0.5
embed_dim = 300
filter_sizes = 3,4,5
num_filters = 256
vocab_size = 124713
learning_rate = 1e-3
num_epochs = 10
max_seq_len = 32
batch_size = 128
vocab_path = data/THUCNews/vocab.pkl
embedding_path = data/THUCNews/embedding.pkl
train_path = data/THUCNews/tokened/train.csv
dev_path = data/THUCNews/tokened/dev.csv
test_path = data/THUCNews/tokened/test.csv
model_path = output/model_data/best_model.pt
result_path = output/result/result.csv

[TextRCNN]
loss_type = ce_loss
embed_dim = 300
hidden_size = 256
num_layers = 2
vocab_size = 124713
learning_rate = 1e-3
dropout = 0.5
num_epochs = 10
max_seq_len = 32
batch_size = 128
vocab_path = data/THUCNews/vocab.pkl
embedding_path = data/THUCNews/embedding.pkl
train_path = data/THUCNews/tokened/train.csv
dev_path = data/THUCNews/tokened/dev.csv
test_path = data/THUCNews/tokened/test.csv
model_path = output/model_data/best_model.pt
result_path = output/result/result.csv

[TextRNN]
hidden_size = 256
num_layers = 2
loss_type = ce_loss
embed_dim = 300
vocab_size = 124713
learning_rate = 1e-3
dropout = 0.5
num_epochs = 10
max_seq_len = 32
batch_size = 128
vocab_path = data/THUCNews/vocab.pkl
embedding_path = data/THUCNews/embedding.pkl
train_path = data/THUCNews/tokened/train.csv
dev_path = data/THUCNews/tokened/dev.csv
test_path = data/THUCNews/tokened/test.csv
model_path = output/model_data/best_model.pt
result_path = output/result/result.csv

[DPCNN]
num_filters = 250
loss_type = ce_loss
embed_dim = 300
vocab_size = 124713
learning_rate = 1e-3
dropout = 0.5
num_epochs = 10
max_seq_len = 32
batch_size = 128
vocab_path = data/THUCNews/vocab.pkl
embedding_path = data/THUCNews/embedding.pkl
train_path = data/THUCNews/tokened/train.csv
dev_path = data/THUCNews/tokened/dev.csv
test_path = data/THUCNews/tokened/test.csv
model_path = output/model_data/best_model.pt
result_path = output/result/result.csv

[BertFC]
loss_type = ce_loss
learning_rate = 2e-5
num_epochs = 10
max_seq_len = 32
batch_size = 128
pre_trained_model = pretrain/chinese_wwm_ext_pytorch
train_path = data/THUCNews/no_tokened/train.csv
dev_path = data/THUCNews/no_tokened/dev.csv
test_path = data/THUCNews/no_tokened/test.csv
model_path = output/model_data/best_model.pt
result_path = output/result/result.csv